{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N81-56fCKaJb"
      },
      "source": [
        "# **Step 1 : Load Tools**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOHX9i34QTBQ",
        "outputId": "3118ffa8-e1dd-44c7-8664-00a963c2f0e7"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/Bank_note_prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4HMk6B-cdkON"
      },
      "outputs": [],
      "source": [
        "# Importing core libraries for data handling and visualization\n",
        "import numpy as np               # NumPy: used for numerical computations, arrays, linear algebra, math functions\n",
        "import pandas as pd              # Pandas: used for data manipulation and analysis (DataFrames, CSV loading, etc.)\n",
        "import matplotlib.pyplot as plt  # Matplotlib: plotting library for creating visualizations like line, bar, scatter plots\n",
        "import seaborn as sns            # Seaborn: advanced visualization library built on Matplotlib, used for heatmaps, pairplots, etc.\n",
        "\n",
        "# Importing essential Scikit-learn modules for ML workflow\n",
        "from sklearn.model_selection import train_test_split  # Splits dataset into training and testing subsets\n",
        "from sklearn.preprocessing import StandardScaler      # Standardizes features by removing mean and scaling to unit variance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  \n",
        "# accuracy_score â†’ Calculates how many predictions are correct\n",
        "# confusion_matrix â†’ Shows true positives, false positives, true negatives, false negatives\n",
        "# classification_report â†’ Provides precision, recall, F1-score, and support for each class\n",
        "\n",
        "# Importing TensorFlow Keras modules for Deep Learning (ANN)\n",
        "from tensorflow.keras.models import Sequential   # Sequential: a linear stack of layers for building ANN models\n",
        "from tensorflow.keras.layers import Dense,Dropout  \n",
        "# Dense â†’ Fully connected neural network layer (every neuron connected to the next layer)\n",
        "# Dropout â†’ Regularization technique that randomly turns off some neurons during training to avoid overfitting\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical  \n",
        "# Converts labels (e.g., 0,1) into one-hot encoded vectors, useful for multi-class classification\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping  \n",
        "# Stops training early if the model performance stops improving (prevents overfitting and saves training time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FGf4-jKls8"
      },
      "source": [
        "# **Step 2 : Load Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jX8iCU2Tcs6"
      },
      "source": [
        "# **About Dataset**\n",
        "# **Context**\n",
        "Banknotes are one of the most important assets of a country. Some miscreants introduce fake notes which bear a resemblance to original notes to create discrepancies in the money in the financial market. It is difficult for humans to tell true and fake banknotes apart especially because they have a lot of similar features.\n",
        "\n",
        "# **Motivation**\n",
        "Despite a decrease in the use of currency due to the recent growth in the use of electronic transactions, cash transactions remain very important in the global market. Banknotes are used to carry out financial activities. To continue with smooth cash transactions, the entry of forged banknotes in circulation should be preserved. There has been a drastic increase in the rate of fake notes in the market. Fake money is an imitation of genuine notes and is created illegally for various motives. These fake notes are created in all denominations which brings the financial market of the country to a low level. The various advancements in the field of scanners and copy machines have led the miscreants to create copies of banknotes. It is difficult for human-eye to recognize a fake note because they are created with great accuracy to look alike a genuine note. Security aspects of banknotes have to be considered and security features are to be introduced to mitigate fake currency. Hence, there is a dire need for banks and ATMs to implement a system that classifies a note as genuine or fake.\n",
        "\n",
        "# **Objective**\n",
        "Being a Data Science Enthusiast, you committed yourself to use the power of Data Science and coming up with an efficient model that accurately predicts if a note is genuine or not.\n",
        "\n",
        "# **About the Data**\n",
        "Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes. Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object grey-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool was used to extract features from images.\n",
        "\n",
        "# **Data Description**\n",
        "\n",
        "VWTI: Variance of Wavelet Transformed Image\n",
        "\n",
        "SWTI: Skewness of Wavelet Transformed Image\n",
        "\n",
        "CWTI: Curtosis of Wavelet Transformed Image\n",
        "\n",
        "EI: Entropy of Image\n",
        "\n",
        "Class: Class (1: genuine, 0: forged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HAt_uE1yW4gX",
        "outputId": "8c98b873-ebd0-4d97-a6c3-7308eba5f2e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "VWTI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SWTI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CWTI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "EI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Class",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "90c4177c-020f-43c7-8fb6-e5fbc28ca2af",
              "rows": [
                [
                  "0",
                  "2.2634",
                  "-4.4862",
                  "3.6558",
                  "-0.61251",
                  "0"
                ],
                [
                  "1",
                  "3.2718",
                  "1.7837",
                  "2.1161",
                  "0.61334",
                  "0"
                ],
                [
                  "2",
                  "-3.9411",
                  "-12.8792",
                  "13.0597",
                  "-3.3125",
                  "1"
                ],
                [
                  "3",
                  "0.5195",
                  "-3.2633",
                  "3.0895",
                  "-0.9849",
                  "0"
                ],
                [
                  "4",
                  "2.5698",
                  "-4.4076",
                  "5.9856",
                  "0.078002",
                  "0"
                ],
                [
                  "5",
                  "-3.793",
                  "-12.7095",
                  "12.7957",
                  "-2.825",
                  "1"
                ],
                [
                  "6",
                  "-2.2987",
                  "-5.227",
                  "5.63",
                  "0.91722",
                  "1"
                ],
                [
                  "7",
                  "-4.0786",
                  "2.9239",
                  "0.87026",
                  "-0.65389",
                  "1"
                ],
                [
                  "8",
                  "2.4486",
                  "-6.3175",
                  "7.9632",
                  "0.2060199999999999",
                  "0"
                ],
                [
                  "9",
                  "1.8993",
                  "7.6625",
                  "0.15394",
                  "-3.1108",
                  "0"
                ],
                [
                  "10",
                  "0.3292",
                  "-4.4552",
                  "4.5718",
                  "-0.9888",
                  "0"
                ],
                [
                  "11",
                  "-0.95403",
                  "1.9824",
                  "-2.3163",
                  "-1.1957",
                  "1"
                ],
                [
                  "12",
                  "-4.0679",
                  "2.4955",
                  "0.79571",
                  "-1.1039",
                  "1"
                ],
                [
                  "13",
                  "-1.5055",
                  "0.070346",
                  "6.8681",
                  "-0.50648",
                  "0"
                ],
                [
                  "14",
                  "0.74841",
                  "7.2756",
                  "1.1504",
                  "-0.5388",
                  "0"
                ],
                [
                  "15",
                  "-0.55648",
                  "3.2136",
                  "-3.3085",
                  "-2.7965",
                  "1"
                ],
                [
                  "16",
                  "3.2403",
                  "-3.7082",
                  "5.2804",
                  "0.41291",
                  "0"
                ],
                [
                  "17",
                  "-3.5985",
                  "-13.6593",
                  "17.6052",
                  "-2.4927",
                  "1"
                ],
                [
                  "18",
                  "-2.0897",
                  "10.8265",
                  "2.3603",
                  "-3.4198",
                  "0"
                ],
                [
                  "19",
                  "-1.3",
                  "10.2678",
                  "-2.9530000000000003",
                  "-5.8638",
                  "0"
                ],
                [
                  "20",
                  "0.5593899999999999",
                  "-0.3104",
                  "0.18307",
                  "0.44653",
                  "1"
                ],
                [
                  "21",
                  "4.1197",
                  "-2.7956",
                  "2.0707",
                  "0.6741199999999999",
                  "0"
                ],
                [
                  "22",
                  "2.0153",
                  "1.8479",
                  "3.1375",
                  "0.42843",
                  "0"
                ],
                [
                  "23",
                  "0.3798",
                  "0.7098",
                  "0.7572",
                  "-0.4444",
                  "0"
                ],
                [
                  "24",
                  "-0.7351",
                  "1.7361",
                  "-1.4938",
                  "-1.1582",
                  "1"
                ],
                [
                  "25",
                  "-3.2854",
                  "4.0372",
                  "-0.45356",
                  "-1.8228",
                  "1"
                ],
                [
                  "26",
                  "2.7213",
                  "7.05",
                  "-0.58808",
                  "0.4180899999999999",
                  "0"
                ],
                [
                  "27",
                  "1.8592",
                  "3.2074",
                  "-0.15966",
                  "-0.26208",
                  "0"
                ],
                [
                  "28",
                  "1.602",
                  "6.1251",
                  "0.5292399999999999",
                  "0.47886",
                  "0"
                ],
                [
                  "29",
                  "3.82",
                  "10.9279",
                  "-4.0112",
                  "-5.0284",
                  "0"
                ],
                [
                  "30",
                  "1.0009",
                  "7.7846",
                  "-0.28219",
                  "-2.6608",
                  "0"
                ],
                [
                  "31",
                  "-1.9881",
                  "0.99945",
                  "-0.28562",
                  "-0.70044",
                  "1"
                ],
                [
                  "32",
                  "-2.2173",
                  "1.4671",
                  "-0.7268899999999999",
                  "-1.1724",
                  "1"
                ],
                [
                  "33",
                  "4.4295",
                  "-2.3507",
                  "1.7048",
                  "0.90946",
                  "0"
                ],
                [
                  "34",
                  "5.7227",
                  "5.8312",
                  "-2.4097",
                  "-0.24527",
                  "0"
                ],
                [
                  "35",
                  "2.9571",
                  "-4.5938",
                  "5.9068",
                  "0.57196",
                  "0"
                ],
                [
                  "36",
                  "4.1038",
                  "-4.8069",
                  "3.3491",
                  "-0.49225",
                  "0"
                ],
                [
                  "37",
                  "0.11592",
                  "3.2219",
                  "-3.4302",
                  "-2.8457",
                  "1"
                ],
                [
                  "38",
                  "2.0962",
                  "2.4769",
                  "1.9379",
                  "-0.040962",
                  "0"
                ],
                [
                  "39",
                  "1.3419",
                  "-4.4221",
                  "8.09",
                  "-1.7349",
                  "0"
                ],
                [
                  "40",
                  "2.4012",
                  "1.6223",
                  "3.0312",
                  "0.7167899999999999",
                  "0"
                ],
                [
                  "41",
                  "-1.6641",
                  "-1.3678",
                  "1.997",
                  "0.52283",
                  "1"
                ],
                [
                  "42",
                  "-4.2091",
                  "4.7283",
                  "-0.49126",
                  "-5.2159",
                  "1"
                ],
                [
                  "43",
                  "-1.8584",
                  "7.886",
                  "-1.6643",
                  "-1.8384",
                  "0"
                ],
                [
                  "44",
                  "-1.7064",
                  "3.3088",
                  "-2.2829",
                  "-2.1978",
                  "1"
                ],
                [
                  "45",
                  "0.066129",
                  "2.4914",
                  "-2.9401",
                  "-0.62156",
                  "1"
                ],
                [
                  "46",
                  "-4.8426",
                  "-4.9932",
                  "10.4052",
                  "-0.53104",
                  "1"
                ],
                [
                  "47",
                  "-3.0201",
                  "-0.6725300000000001",
                  "2.7056",
                  "0.85774",
                  "1"
                ],
                [
                  "48",
                  "3.2051",
                  "8.6889",
                  "-2.9033",
                  "-0.7819",
                  "0"
                ],
                [
                  "49",
                  "-3.551",
                  "1.8955",
                  "0.1865",
                  "-2.4409",
                  "1"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 1096
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VWTI</th>\n",
              "      <th>SWTI</th>\n",
              "      <th>CWTI</th>\n",
              "      <th>EI</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.263400</td>\n",
              "      <td>-4.4862</td>\n",
              "      <td>3.65580</td>\n",
              "      <td>-0.612510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.271800</td>\n",
              "      <td>1.7837</td>\n",
              "      <td>2.11610</td>\n",
              "      <td>0.613340</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3.941100</td>\n",
              "      <td>-12.8792</td>\n",
              "      <td>13.05970</td>\n",
              "      <td>-3.312500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.519500</td>\n",
              "      <td>-3.2633</td>\n",
              "      <td>3.08950</td>\n",
              "      <td>-0.984900</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.569800</td>\n",
              "      <td>-4.4076</td>\n",
              "      <td>5.98560</td>\n",
              "      <td>0.078002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>1.640600</td>\n",
              "      <td>3.5488</td>\n",
              "      <td>1.39640</td>\n",
              "      <td>-0.364240</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>-0.048008</td>\n",
              "      <td>-1.6037</td>\n",
              "      <td>8.47560</td>\n",
              "      <td>0.755580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>2.942100</td>\n",
              "      <td>7.4101</td>\n",
              "      <td>-0.97709</td>\n",
              "      <td>-0.884060</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>1.964700</td>\n",
              "      <td>6.9383</td>\n",
              "      <td>0.57722</td>\n",
              "      <td>0.663770</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>-0.126240</td>\n",
              "      <td>10.3216</td>\n",
              "      <td>-3.71210</td>\n",
              "      <td>-6.118500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1096 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          VWTI     SWTI      CWTI        EI  Class\n",
              "0     2.263400  -4.4862   3.65580 -0.612510      0\n",
              "1     3.271800   1.7837   2.11610  0.613340      0\n",
              "2    -3.941100 -12.8792  13.05970 -3.312500      1\n",
              "3     0.519500  -3.2633   3.08950 -0.984900      0\n",
              "4     2.569800  -4.4076   5.98560  0.078002      0\n",
              "...        ...      ...       ...       ...    ...\n",
              "1091  1.640600   3.5488   1.39640 -0.364240      0\n",
              "1092 -0.048008  -1.6037   8.47560  0.755580      0\n",
              "1093  2.942100   7.4101  -0.97709 -0.884060      0\n",
              "1094  1.964700   6.9383   0.57722  0.663770      0\n",
              "1095 -0.126240  10.3216  -3.71210 -6.118500      0\n",
              "\n",
              "[1096 rows x 5 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Dataset\n",
        "data = pd.read_csv(\"./data/train.csv\")  \n",
        "# ğŸ“Œ pd.read_csv â†’ Reads a CSV file and loads it into a Pandas DataFrame.\n",
        "# \"./data/train.csv\" â†’ Path to the dataset (inside a 'data' folder, file named 'train.csv').\n",
        "# The resulting 'data' variable will now hold the entire dataset in a tabular (row-column) structure.\n",
        "\n",
        "data  \n",
        "# ğŸ“Œ Displays the contents of the DataFrame (usually the first 20 rows by default in notebooks like Jupyter/Colab).\n",
        "# Useful for quickly checking if the dataset was loaded correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqlBULLvkjTw"
      },
      "source": [
        "# **Step 3 : Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGha484jkop7",
        "outputId": "4196dce7-acba-4654-c1c0-6fb0ed895b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (700, 4), y_train shape: (700,)\n",
            "X_val shape: (176, 4), y_val shape: (176,)\n",
            "X_test shape: (220, 4), y_test shape: (220,)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target\n",
        "X = data[['VWTI', 'SWTI', 'CWTI', 'EI']]  \n",
        "# ğŸ“Œ 'X' holds the independent variables (features) used to predict the target.\n",
        "# Here, we select the columns 'VWTI', 'SWTI', 'CWTI', and 'EI' from the dataset as inputs.\n",
        "\n",
        "y = data['Class']  \n",
        "# ğŸ“Œ 'y' is the dependent variable (target), which we want to predict (e.g., 0 = fake note, 1 = real note).\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
        "# ğŸ“Œ Splits the dataset into training and testing sets.\n",
        "# test_size=0.2 â†’ 20% of the data is reserved for testing, 80% for training.\n",
        "# random_state=42 â†’ ensures reproducibility (same split every run).\n",
        "\n",
        "\n",
        "# Further split training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  \n",
        "# ğŸ“Œ Further splits the training set into training (64%) and validation (16%).\n",
        "# Validation set helps tune hyperparameters and monitor model performance during training.\n",
        "\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()  \n",
        "# ğŸ“Œ Creates a StandardScaler object to normalize features.\n",
        "# StandardScaler transforms features so they have mean = 0 and standard deviation = 1.\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)  \n",
        "# ğŸ“Œ Fits the scaler on training data (learns mean & std) and applies scaling.\n",
        "# Always fit only on training data to prevent data leakage.\n",
        "\n",
        "X_val = scaler.transform(X_val)  \n",
        "# ğŸ“Œ Uses the scaler fitted on training data to scale validation features.\n",
        "\n",
        "X_test = scaler.transform(X_test)  \n",
        "# ğŸ“Œ Uses the same scaler to scale test features (ensures consistency across datasets).\n",
        "\n",
        "\n",
        "# Ensure target is in binary format (0 or 1 for binary classification)\n",
        "# No need for one-hot encoding in binary classification\n",
        "y_train = y_train.values  \n",
        "y_val = y_val.values  \n",
        "y_test = y_test.values  \n",
        "# ğŸ“Œ Converts the target Series into NumPy arrays for compatibility with ML/DL models.\n",
        "# Since it's binary classification (0 or 1), one-hot encoding isnâ€™t required.\n",
        "\n",
        "\n",
        "# Check shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")  \n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")  \n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")  \n",
        "# ğŸ“Œ Prints the shape (rows, columns) of each dataset to confirm splits are correct.\n",
        "# Helps verify that features and targets align properly in each set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltr89cXxro3u"
      },
      "source": [
        "# **Step 4 : Build the ANN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78g-vOUusbpb",
        "outputId": "e4d35ad8-daea-4828-bc56-bb613315713f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "Gm_ftL7XrvLQ",
        "outputId": "8bd71c1a-205a-4b92-f2bd-00503394298a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kevin\\Documents\\my projects\\Building Fake Bank Notes Detection System Using Deep learning ANN\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m528\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential([  \n",
        "    # ğŸ“Œ Sequential means layers are stacked one after another in order.\n",
        "    \n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  \n",
        "    # ğŸ“Œ First hidden layer (Dense = fully connected layer).\n",
        "    # 64 neurons, ReLU activation function.\n",
        "    # input_shape=(X_train.shape[1],) â†’ number of input features (columns).\n",
        "    # This is the entry point for our ANN.\n",
        "    \n",
        "    Dropout(0.3),  \n",
        "    # ğŸ“Œ Randomly drops 30% of neurons during training.\n",
        "    # Prevents overfitting by ensuring the network doesnâ€™t rely too much on specific neurons.\n",
        "    \n",
        "    Dense(32, activation='relu'),  \n",
        "    # ğŸ“Œ Second hidden layer with 32 neurons and ReLU activation.\n",
        "    # Reduces dimensionality and extracts deeper patterns.\n",
        "    \n",
        "    Dropout(0.3),  \n",
        "    # ğŸ“Œ Another Dropout layer to improve generalization.\n",
        "    \n",
        "    Dense(16, activation='relu'),  \n",
        "    # ğŸ“Œ Third hidden layer with 16 neurons and ReLU activation.\n",
        "    # Further condenses feature representations.\n",
        "    \n",
        "    Dense(1, activation='sigmoid')  \n",
        "    # ğŸ“Œ Output layer with 1 neuron.\n",
        "    # Sigmoid activation squashes values between 0 and 1 â†’ ideal for binary classification (fake vs real).\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  \n",
        "    # ğŸ“Œ Adam optimizer â†’ efficient gradient descent algorithm for fast convergence.\n",
        "    \n",
        "    loss='binary_crossentropy',  \n",
        "    # ğŸ“Œ Binary crossentropy loss function â†’ standard for binary classification problems.\n",
        "    \n",
        "    metrics=['accuracy']  \n",
        "    # ğŸ“Œ Weâ€™ll track accuracy during training/validation/testing.\n",
        ")\n",
        "\n",
        "\n",
        "# Add early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',          # ğŸ“Œ Watches validation loss.\n",
        "    patience=5,                  # ğŸ“Œ If no improvement for 5 epochs â†’ stop training.\n",
        "    restore_best_weights=True    # ğŸ“Œ Roll back to the epoch with the best validation loss.\n",
        ")\n",
        "\n",
        "\n",
        "# Check model summary\n",
        "model.summary()  \n",
        "# ğŸ“Œ Prints the architecture of the ANN:\n",
        "# - Layer types (Dense, Dropout)\n",
        "# - Output shapes\n",
        "# - Number of trainable parameters\n",
        "# Useful to confirm the network is built as expected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWtHcJjxuKiW"
      },
      "source": [
        "# **Step 5 : Train The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTqXr-a-uQPL",
        "outputId": "2aa9e0f0-4f81-4b86-afdf-ae5b29261789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.5971 - loss: 0.6636 - val_accuracy: 0.8125 - val_loss: 0.6085\n",
            "Epoch 2/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7729 - loss: 0.5823 - val_accuracy: 0.8523 - val_loss: 0.5031\n",
            "Epoch 3/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8614 - loss: 0.4801 - val_accuracy: 0.8750 - val_loss: 0.3829\n",
            "Epoch 4/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9171 - loss: 0.3636 - val_accuracy: 0.9261 - val_loss: 0.2730\n",
            "Epoch 5/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9414 - loss: 0.2599 - val_accuracy: 0.9602 - val_loss: 0.1809\n",
            "Epoch 6/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9586 - loss: 0.1719 - val_accuracy: 0.9602 - val_loss: 0.1249\n",
            "Epoch 7/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9743 - loss: 0.1187 - val_accuracy: 0.9830 - val_loss: 0.0926\n",
            "Epoch 8/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9714 - loss: 0.1051 - val_accuracy: 0.9773 - val_loss: 0.0679\n",
            "Epoch 9/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9714 - loss: 0.0904 - val_accuracy: 0.9830 - val_loss: 0.0596\n",
            "Epoch 10/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9814 - loss: 0.0649 - val_accuracy: 0.9830 - val_loss: 0.0519\n",
            "Epoch 11/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9714 - loss: 0.0690 - val_accuracy: 0.9830 - val_loss: 0.0434\n",
            "Epoch 12/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0545 - val_accuracy: 0.9830 - val_loss: 0.0306\n",
            "Epoch 13/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9800 - loss: 0.0465 - val_accuracy: 0.9830 - val_loss: 0.0294\n",
            "Epoch 14/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9929 - loss: 0.0313 - val_accuracy: 0.9830 - val_loss: 0.0242\n",
            "Epoch 15/15\n",
            "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 0.0161\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(  \n",
        "    X_train, y_train,  \n",
        "    # ğŸ“Œ Training data (features and labels).\n",
        "    # The model will learn patterns from these samples.\n",
        "    \n",
        "    validation_data=(X_val, y_val),  \n",
        "    # ğŸ“Œ Validation set â†’ evaluates model performance after each epoch.\n",
        "    # Used to monitor overfitting (model doing well on train but poorly on unseen data).\n",
        "    \n",
        "    epochs=15,  \n",
        "    # ğŸ“Œ Maximum number of times the model sees the entire dataset.\n",
        "    # Here, 15 passes through the training set.\n",
        "    \n",
        "    batch_size=32,  \n",
        "    # ğŸ“Œ Number of samples processed before updating weights.\n",
        "    # Smaller batch size â†’ more updates, but slower training.\n",
        "    # 32 is a standard balance for speed and stability.\n",
        "    \n",
        "    callbacks=[early_stopping]  \n",
        "    # ğŸ“Œ Uses EarlyStopping (defined earlier).\n",
        "    # Training will stop before 15 epochs if validation loss doesnâ€™t improve for 5 consecutive epochs.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5AjF3p7uZNo"
      },
      "source": [
        "# **Step 6 : Evaluate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I_1Y5utugNy",
        "outputId": "d8a01faa-5a2b-4c98-c968-169d59ffec21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9864 - loss: 0.0227\n",
            "Test Loss: 0.0227, Test Accuracy: 0.9864\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)  \n",
        "# ğŸ“Œ model.evaluate â†’ Runs the model on the test dataset.\n",
        "# - X_test: test features (scaled inputs).\n",
        "# - y_test: true labels (ground truth).\n",
        "# Returns two values:\n",
        "#   test_loss â†’ the loss value on test data (how far predictions are from true labels).\n",
        "#   test_acc  â†’ accuracy on test data (fraction of correct predictions).\n",
        "\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")  \n",
        "# ğŸ“Œ Prints test performance in a human-readable format.\n",
        "# :.4f â†’ formats the numbers to 4 decimal places.\n",
        "# Example output: Test Loss: 0.2456, Test Accuracy: 0.9523\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_LAeizNuibz"
      },
      "source": [
        "# **7. Generate Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNTGBAIbuoVv",
        "outputId": "80cd042f-2bfc-4b25-8a57-0a2f1cec6230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       135\n",
            "           1       0.97      1.00      0.98        85\n",
            "\n",
            "    accuracy                           0.99       220\n",
            "   macro avg       0.98      0.99      0.99       220\n",
            "weighted avg       0.99      0.99      0.99       220\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions for the test dataset using the trained model.\n",
        "# The model.predict(X_test) outputs probabilities between 0 and 1 for each sample.\n",
        "# ( > 0.5 ) converts probabilities to binary class labels: values > 0.5 become True (1), otherwise False (0).\n",
        "# .astype(int) converts the boolean values (True/False) into integers (1/0) for classification.\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Print a header to indicate that the following output is the classification report.\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "# Generate and print a detailed classification report comparing the true labels (y_test)\n",
        "# with the predicted labels (y_pred). \n",
        "# This report includes metrics like precision, recall, f1-score, and support for each class.\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "kpn1UaCQuspZ",
        "outputId": "dcf3cbec-d095-4faf-c14a-7d51943dc4b9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import the seaborn library for creating advanced visualizations\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute the confusion matrix comparing true labels (y_test) to predicted labels (y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Create a new figure for the plot with a size of 6 inches by 5 inches\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Plot the confusion matrix using seaborn's heatmap function\n",
        "# - cm: the confusion matrix data\n",
        "# - annot=True: write the data values on each cell\n",
        "# - fmt='d': format numbers as integers\n",
        "# - cmap='Blues': use a blue color palette\n",
        "# - xticklabels and yticklabels: label the axes with class names\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Class 0', 'Class 1'], \n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel('True')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtkRe6oiu0NI"
      },
      "source": [
        "# **Step 8: Prediction System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "_UxXq2aEu7iF"
      },
      "outputs": [],
      "source": [
        "# Import numpy library for numerical operations (arrays, matrices, etc.)\n",
        "import numpy as np\n",
        "\n",
        "# Define a function called make_prediction that takes input_data as argument\n",
        "def make_prediction(input_data):\n",
        "    \n",
        "    # Preprocess the input data before feeding it to the model\n",
        "    # Scale the input using a pre-fitted scaler (assumes `scaler` is already trained)\n",
        "    # transform() scales the input data based on the parameters learned from training data\n",
        "    input_data_scaled = scaler.transform(input_data)  # Do not use fit_transform to avoid refitting\n",
        "    \n",
        "    # Use the trained model to predict probabilities for the scaled input data\n",
        "    predictions = model.predict(input_data_scaled)\n",
        "    \n",
        "    # Convert the predicted probabilities to binary class labels (0 or 1)\n",
        "    # Any probability > 0.5 is considered class 1, otherwise class 0\n",
        "    predicted_classes = (predictions > 0.5).astype(int)\n",
        "    \n",
        "    # Return a human-readable string based on the predicted class\n",
        "    # If the predicted class is 1, return \"Real\"; otherwise, return \"Fake\"\n",
        "    if predicted_classes[0] == 1:\n",
        "        return \"Real\"\n",
        "    else:\n",
        "        return \"Fake\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUEvQ6xXu-2a",
        "outputId": "504e193b-c96c-487c-a06e-f9e34d2ddb0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kevin\\Documents\\my projects\\Building Fake Bank Notes Detection System Using Deep learning ANN\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "Fake\n"
          ]
        }
      ],
      "source": [
        "# Create example input data as a NumPy array\n",
        "# Each row represents one sample and each column represents a feature\n",
        "# Replace these numbers with actual data from a form or dataset\n",
        "input_data = np.array([[1.5, 2.3, 3.4, 0.7]])  # Example features\n",
        "\n",
        "# Call the make_prediction function defined earlier\n",
        "# This function will preprocess the data, make a prediction, and return \"Real\" or \"Fake\"\n",
        "result = make_prediction(input_data)\n",
        "\n",
        "# Print the prediction result to the console\n",
        "# Output will be either \"Real\" or \"Fake\" based on the model's prediction\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAcRm4r8vCoW",
        "outputId": "174556e1-a136-4c56-8d30-6b7e3509d36e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kevin\\Documents\\my projects\\Building Fake Bank Notes Detection System Using Deep learning ANN\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "Real\n"
          ]
        }
      ],
      "source": [
        "# Create example input data as a NumPy array\n",
        "# Each row is a single sample, and each column represents a feature\n",
        "# Replace the numbers with actual input values from your form or dataset\n",
        "input_data = np.array([[-3.9411, -12.8792,  13.0597,  -3.3125]])  # Example features\n",
        "\n",
        "# Call the make_prediction function to get the prediction for this input\n",
        "# The function will scale the input, use the trained model to predict, \n",
        "# and return \"Real\" or \"Fake\"\n",
        "result = make_prediction(input_data)\n",
        "\n",
        "# Print the prediction result\n",
        "# Output will be \"Real\" if the model predicts class 1, or \"Fake\" if it predicts class 0\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0uwIowLvFvY"
      },
      "source": [
        "\n",
        "# **Step 9: Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LURiTz1gvI8B",
        "outputId": "a35e87ac-1b1e-4518-a480-6a58869b8bc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the trained model to a file in HDF5 format\n",
        "# 'models/model.h5' is the file path where the model will be stored\n",
        "# This allows you to reload the model later without retraining\n",
        "model.save('models/model.h5')\n",
        "\n",
        "# Save the pre-fitted scaler using Python's pickle module\n",
        "# Open a file in write-binary mode ('wb') to store the scaler object\n",
        "with open('models/scaler.pkl', 'wb') as scaler_file:\n",
        "    # Dump the scaler object into the file\n",
        "    # This preserves the scaling parameters (mean, variance) for future use\n",
        "    pickle.dump(scaler, scaler_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
